{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepDream - fr",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwyOJxH4ynqv"
      },
      "source": [
        "# Deep Dream - français\n",
        "Original version // version originale:  https://www.tensorflow.org/tutorials/generative/deepdream"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsYIQv6XSAvf"
      },
      "source": [
        "## Licence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBLAf1ITR-0x"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAoaULsrR-gt"
      },
      "source": [
        "Ce tutorial présente une implémentation minimale de DeepDream, tel que décrit par Alexander Mordvintsev sur son blog.\n",
        "\n",
        "DeepDream est une expérience visant à visualiser les patrons ou motifs appris par un réseau de neurones. De façon similaire à l'enfant qui regarde les nuages tout en essayant d'interpréter des formes aléatoires, DeepDream sur-interprète et met de l'avant les motifs qu'il voit dans les images.\n",
        "\n",
        "Pour ce faire, il transmet une image au travers du réseau, puis calcule le gradient de l'image en rapport aux activations d'une couche spécifique. Par la suite, l'image est modifiée de façon à augmenter la valeur prise par ces activations, de ce fait même améliorant les motifs et patrons vus par le réseau et donnant une impression de rêve. Ce processus a été surnommé \"Inceptionism\" (une référence à InceptionNet et au film Inception).\n",
        "\n",
        "Voici une démonstration d'un tel rêve.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0saxIa0aSPjX"
      },
      "source": [
        "## programmons !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TC-4hsAyio6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkc1G1acSXX4"
      },
      "source": [
        "Pour ce tutoriel, nous allons utiliser l'image d'un labrador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cRS2Ej4SXp3"
      },
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdwjei6Sjmv"
      },
      "source": [
        "Commençons par définir quelques fonctions adjacentes dont nous aurons besoin plus tard.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyH51cRdSqoY"
      },
      "source": [
        "# Télécharger une image et la stocker dans un tableau NumPy,\n",
        "def download(url, max_dim=None):\n",
        "  name = url.split('/')[-1]\n",
        "  image_path = tf.keras.utils.get_file(name, origin=url)\n",
        "  img = PIL.Image.open(image_path)\n",
        "  if max_dim:\n",
        "    img.thumbnail((max_dim, max_dim))\n",
        "  return np.array(img)\n",
        "\n",
        "# Normaliser une image\n",
        "def deprocess(img):\n",
        "  img = 255*(img + 1.0)/2.0\n",
        "  return tf.cast(img, tf.uint8)\n",
        "\n",
        "# Montrer une image\n",
        "def show(img):\n",
        "  PIL.Image.fromarray(np.array(img)).show()\n",
        "\n",
        "def save_img(filename, img):\n",
        "  PIL.Image.fromarray(img).save(filename, 'png')\n",
        "\n",
        "def load_img(filename, max_dim=None):\n",
        "  img = PIL.Image.open(filename)\n",
        "  if max_dim:\n",
        "    img.thumbnail((max_dim, max_dim))\n",
        "  return np.array(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_BQiZuGSq6b"
      },
      "source": [
        "# Préparer le modèle d'extraction des caractéristiques\n",
        "\n",
        "Téléchargez et préparez un modèle pré-entraîné de classification d'images. Nous allons utiliesr InceptionV3 qui est similaire au modèle originalement utilisé dans DeepDream. Notez que n'importe quel modèle pré-entraîné fonctionnera, quoiqu'il soit probable que vous deviez alors changer les noms des couches (*layer*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQP9CBtES2Xw"
      },
      "source": [
        "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_d2yAyvS26R"
      },
      "source": [
        "L'idée de DeepDream est de choisir une ou des couches et de maximiser la \"perte\" de façon que les images puissent \"activer\" les couches.\n",
        "\n",
        "La complexité des caractéristiques incorporées dépend des couches que nous choisissons, c'est-à-dire que des couches inférieures produisent des traits ou des motifs simples, alors que les couches ultérieures produisent des caractéristiques sophistiquées dans les images, voire même des objets complets.\n",
        "\n",
        "L'architecture du modèle InceptionV3 est plutôt imposante - pour voir une image de cette architecture, consultez le dossier de recherche de TensorFlow). \n",
        "\n",
        "Pour DeepDream, les couches d'intérêt sont celles où les convolutions sont concaténées. Il y a onze couches concaténées dans InceptionV3, nommées de 'mixed0' jusqu'à 'mixed10'. L'utilisation de couches différentes donnera des images surréelles différentes.\n",
        "\n",
        "Les couches ultérieures ont une réaction lorsqu'elles sont en contact avec des caractéristiques de haut niveau, comme des yeux et des visages, alors que les couches inférieures sont activées par des caractéristiques plus simples, comme des arêtes, des formes et des textures.\n",
        "\n",
        "Vous pouvez expérimenter avec le code ci-bas, mais gardez en tête que les couches ultérieures (celles avec un index plus élevé) prennent plus de temps à entraîner car le calcul du gradient est plus long.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTZq0TceS-fh"
      },
      "source": [
        "# Maximiser l'activation de ces couches\n",
        "names = ['mixed3', 'mixed5']\n",
        "layers = [base_model.get_layer(name).output for name in names]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eghQtOcTA4s"
      },
      "source": [
        "# Créer le modèle d'extraction des caractéristiques\n",
        "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXScWn0CTDYy"
      },
      "source": [
        "# Calculer la fonction objectif\n",
        "\n",
        "La valeur de la fonction objectif est la somme des activations des couches sélectionnées.\n",
        "\n",
        "La valeur est normalisée à chaque couche de façon à ce que les apports des couches larges ne puissent pas prendre le dessus sur les couches plus petites. Normalement, on souhaite minimiser la valeur prise par la fonction objectif, par la méthode de la descente du gradient. Dans DeepDream, nous allons maximiser cette valeur par le biais de l'ascension du gradient.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1fyPNNcTD4k"
      },
      "source": [
        "def calc_loss(img, model):\n",
        "  # Déplacer l'image vers l'avant du modèle de façon à aller chercher les activations.\n",
        "  # Convertir l'image en une batch de taille 1.\n",
        "  img_batch = tf.expand_dims(img, axis=0)\n",
        "  layer_activations = model(img_batch)\n",
        "\n",
        "  losses = []\n",
        "  for act in layer_activations:\n",
        "    loss = tf.math.reduce_mean(act)\n",
        "    losses.append(loss)\n",
        "\n",
        "  return  tf.reduce_sum(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DOs2UmMTKAU"
      },
      "source": [
        "# Ascension du gradient\n",
        "\n",
        "Après avoir calculer la valeur de la fonction objectif pour les couches choisies, tout ce qu'il reste à faire est de calculer les gradients de l'image, et de les ajouter à l'image originale.\n",
        "\n",
        "Le fait d'ajouter les gradients à l'image met de l'avant les motifs vus par le réseau de neurones. Chaque étape permet de créer une image qui augmente de plus en plus les activations de certaines couches du réseau.\n",
        "\n",
        "La méthode réalisant cette étape est imbriquée dans une fonction `tf.function` pour plus de performance. Elle utilise `input_signature` afin d'assurer que la fonction n'est pas \"retracée\" pour des images de taille différente ou pour différentes valeurs de steps/step_size.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8DufxuTTKaw"
      },
      "source": [
        "class DeepDream(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function(\n",
        "      input_signature=(\n",
        "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
        "  )\n",
        "  def __call__(self, img, steps, step_size):\n",
        "      print('Dreaming...😪💤')\n",
        "      loss = tf.constant(0.0)\n",
        "      for _ in tf.range(steps):\n",
        "        with tf.GradientTape() as tape:\n",
        "          # Ici, nous avons besoin de gradients en lien avec 'img'\n",
        "          # Par défaut, 'Gradient Tape' surveille uniquement les `tf.Variable`s\n",
        "          tape.watch(img)\n",
        "          loss = calc_loss(img, self.model)\n",
        "        \n",
        "        # Calcule le gradient de la fonction objectif en rapport aux pixels de l'image d'entrée.\n",
        "        gradients = tape.gradient(loss, img)\n",
        "\n",
        "        # Normalise les gradients.\n",
        "        gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
        "        \n",
        "        # Dans l'ascension du gradient, la valeur de la fonction objectif est maximisée de façon à ce que l'image d'entrée\n",
        "        # active de plus en plus les couches du réseau.\n",
        "        # Vous pouvez mettre à jour l'image en ajoutant directement les gradients à l'image (ceux-ci étant de la même forme).\n",
        "        img = img + gradients*step_size\n",
        "        img = tf.clip_by_value(img, -1, 1)\n",
        "      return loss, img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl4V1kI1TVHV"
      },
      "source": [
        "deepdream = DeepDream(dream_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ojBIPSJTZdG"
      },
      "source": [
        "# Boucle principale\n",
        "\n",
        "Nous sommes maintenant paré.e.s à rouler DeepDream sur notre image !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2bC0JYiywqe"
      },
      "source": [
        "def run_deep_dream_simple(img, steps=100, step_size=0.01):\n",
        "  # Passer de uint8 aux valeurs attendues par le modèle.\n",
        "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "  img = tf.convert_to_tensor(img)\n",
        "  step_size = tf.convert_to_tensor(step_size)\n",
        "  steps_remaining = steps\n",
        "  step = 0\n",
        "  while steps_remaining:\n",
        "    if steps_remaining>100:\n",
        "      run_steps = tf.constant(100)\n",
        "    else:\n",
        "      run_steps = tf.constant(steps_remaining)\n",
        "    steps_remaining -= run_steps\n",
        "    step += run_steps\n",
        "\n",
        "    loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
        "\n",
        "    print (\"Step {}, loss {}\".format(step, loss))\n",
        "\n",
        "  result = deprocess(img)\n",
        "  show(result)\n",
        "\n",
        "  return np.array(result)\n",
        "\n",
        "dream_img = run_deep_dream_simple(img=download(url),\n",
        "                                steps=100, step_size=0.01)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuj9A2ERTiNR"
      },
      "source": [
        "Regardons le résultat..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo2YTzAc0OGg"
      },
      "source": [
        "plt.imshow(dream_img);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}